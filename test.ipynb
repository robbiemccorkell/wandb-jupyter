{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update imports when files change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a (relatively) minimal example of using Ray Tune and Pytorch Lightning to train a fully connected network with optimal hyperparameters on an iris dataset.\n",
    "\n",
    "The `hpo` method is provided to kick off an example training process, and repeated to help test wandb logging within a jupyter notebook.\n",
    "\n",
    "To demonstrate the different methods of logging in this environment, the `logger` argument is provided.\n",
    "\n",
    "- `logger=\"lightning` will use the `lightning.pytorch.loggers.WandbLogger` module to log the results within each HPO trial.\n",
    "- `logger=\"ray\"` will use the `ray.air.integrations.wandb.WandbLoggerCallback` module to log the results as part of the HPO Tuner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpo import hpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First run with `logger=\"lightning\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-16 11:20:34</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.19        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.6/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">   val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_be64b_00000</td><td>TERMINATED</td><td>127.0.0.1:91800</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">     0.00114564</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         6.60775</td><td style=\"text-align: right;\"> 0.0794688  </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">0.0072518  </td></tr>\n",
       "<tr><td>train_tune_be64b_00001</td><td>TERMINATED</td><td>127.0.0.1:91797</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">     0.00423977</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         6.58501</td><td style=\"text-align: right;\"> 0.0781783  </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">0.00515614 </td></tr>\n",
       "<tr><td>train_tune_be64b_00002</td><td>TERMINATED</td><td>127.0.0.1:91798</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">     0.0423807 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         5.05954</td><td style=\"text-align: right;\"> 2.16084e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">5.52176e-05</td></tr>\n",
       "<tr><td>train_tune_be64b_00003</td><td>TERMINATED</td><td>127.0.0.1:91801</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     0.019643  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         4.27401</td><td style=\"text-align: right;\"> 0.00369946 </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">0.119968   </td></tr>\n",
       "<tr><td>train_tune_be64b_00004</td><td>TERMINATED</td><td>127.0.0.1:91799</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">     0.00540065</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         6.50901</td><td style=\"text-align: right;\"> 0.000189246</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">0.00209657 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_tune pid=91800)\u001b[0m GPU available: True (mps), used: True\n",
      "\u001b[36m(train_tune pid=91800)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(train_tune pid=91800)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(train_tune pid=91800)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: Tracking run with wandb version 0.18.7\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: Run data is saved locally in ./wandb/run-20241216_112027-ytarmgyl\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: Syncing run brisk-cloud-115\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/leap-labs/hanging-runs-test-2\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: üöÄ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/ytarmgyl\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m \n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 0 | model   | Sequential       | 1.3 K  | train\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 1.3 K     Trainable params\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 1.3 K     Total params\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 7         Modules in train mode\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=91800)\u001b[0m \n",
      "\u001b[36m(train_tune pid=91797)\u001b[0m \n",
      "\u001b[36m(train_tune pid=91801)\u001b[0m \n",
      "\u001b[36m(train_tune pid=91801)\u001b[0m 0 | model   | Sequential       | 403    | train\n",
      "\u001b[36m(train_tune pid=91801)\u001b[0m 403       Trainable params\n",
      "\u001b[36m(train_tune pid=91801)\u001b[0m 403       Total params\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m \n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-20-22/train_tune_be64b_00004_4_batch_size=16,hidden_dim=32,learning_rate=0.0054_2024-12-16_11-20-24/checkpoint_000000)\n",
      "\u001b[36m(train_tune pid=91801)\u001b[0m `Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m GPU available: True (mps), used: True\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91799)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m wandb: Tracking run with wandb version 0.18.7\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m wandb: Run data is saved locally in ./wandb/run-20241216_112027-5etw0a0v\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m wandb: Syncing run fine-planet-117\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m wandb: üöÄ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/5etw0a0v\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m   | Name    | Type             | Params | Mode \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m -----------------------------------------------------\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 0 | model   | Sequential       | 17.5 K | train\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 17.5 K    Trainable params\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 0         Non-trainable params\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 17.5 K    Total params\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 0.070     Total estimated model params size (MB)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 7         Modules in train mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m 0         Modules in eval mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91798)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=91800)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-20-22/train_tune_be64b_00000_0_batch_size=16,hidden_dim=128,learning_rate=0.0011_2024-12-16_11-20-24/checkpoint_000093)\u001b[32m [repeated 477x across cluster]\u001b[0m\n",
      "2024-12-16 11:20:34,225\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-20-22' in 0.0095s.\n",
      "2024-12-16 11:20:34,229\tINFO tune.py:1041 -- Total run time: 10.21 seconds (10.18 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'hidden_dim': 128, 'learning_rate': 0.042380710301649104, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a863725f7bb4d2da9e786ede1a0a697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.369 MB of 0.369 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ff730eca-train</strong> at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2/runs/x5fzgs7n' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2/runs/x5fzgs7n</a><br/> View project at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241216_112022-x5fzgs7n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 2.1608393581118435e-05, 'train_accuracy': 1.0, 'val_loss': 5.521763159777038e-05, 'val_accuracy': 1.0, 'epoch': 99, 'step': 400},\n",
       "  path='/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-20-22/train_tune_be64b_00002_2_batch_size=32,hidden_dim=128,learning_rate=0.0424_2024-12-16_11-20-24',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-20-22/train_tune_be64b_00002_2_batch_size=32,hidden_dim=128,learning_rate=0.0424_2024-12-16_11-20-24/checkpoint_000099)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1734348286 ***\n",
      "PC: @        0x18bd33efc  (unknown)  kevent\n",
      "    @        0x144a5b964  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "    @        0x18bda4184  (unknown)  _sigtramp\n",
      "    @        0x105ad07ac  (unknown)  select_kqueue_control_impl\n",
      "    @        0x1053a79d4  (unknown)  method_vectorcall_FASTCALL\n",
      "    @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1053a59e4  (unknown)  method_vectorcall\n",
      "    @        0x1053ed244  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10526c250  (unknown)  _PyEval_Vector\n",
      "    @        0x1052a2514  (unknown)  builtin_exec\n",
      "    @        0x1053bb218  (unknown)  cfunction_vectorcall_FASTCALL\n",
      "    @        0x1051d8ce4  (unknown)  call_function\n",
      "    @        0x1053ed70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1051d8ce4  (unknown)  call_function\n",
      "    @        0x1053ed70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1052f5888  (unknown)  pymain_run_module\n",
      "    @        0x1052f4250  (unknown)  Py_RunMain\n",
      "    @        0x10540efac  (unknown)  Py_BytesMain\n",
      "    @        0x18b9ec274  (unknown)  start\n",
      "[2024-12-16 11:24:46,754 E 91713 133560039] logging.cc:447: *** SIGTERM received at time=1734348286 ***\n",
      "[2024-12-16 11:24:46,755 E 91713 133560039] logging.cc:447: PC: @        0x18bd33efc  (unknown)  kevent\n",
      "[2024-12-16 11:24:46,755 E 91713 133560039] logging.cc:447:     @        0x144a5ba84  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "[2024-12-16 11:24:46,755 E 91713 133560039] logging.cc:447:     @        0x18bda4184  (unknown)  _sigtramp\n",
      "[2024-12-16 11:24:46,755 E 91713 133560039] logging.cc:447:     @        0x105ad07ac  (unknown)  select_kqueue_control_impl\n",
      "[2024-12-16 11:24:46,755 E 91713 133560039] logging.cc:447:     @        0x1053a79d4  (unknown)  method_vectorcall_FASTCALL\n",
      "[2024-12-16 11:24:46,755 E 91713 133560039] logging.cc:447:     @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x1053ed130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,756 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1053a59e4  (unknown)  method_vectorcall\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1053ed244  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x10526c250  (unknown)  _PyEval_Vector\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1052a2514  (unknown)  builtin_exec\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1053bb218  (unknown)  cfunction_vectorcall_FASTCALL\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1051d8ce4  (unknown)  call_function\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1053ed70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1051d8ce4  (unknown)  call_function\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1053ed70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x10520f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:24:46,757 E 91713 133560039] logging.cc:447:     @        0x1052f5888  (unknown)  pymain_run_module\n",
      "[2024-12-16 11:24:46,758 E 91713 133560039] logging.cc:447:     @        0x1052f4250  (unknown)  Py_RunMain\n",
      "[2024-12-16 11:24:46,758 E 91713 133560039] logging.cc:447:     @        0x10540efac  (unknown)  Py_BytesMain\n",
      "[2024-12-16 11:24:46,758 E 91713 133560039] logging.cc:447:     @        0x18b9ec274  (unknown)  start\n",
      "[2024-12-16 11:24:46,865 E 91713 133560687] core_worker.cc:786: :info_message: Attempting to recover 3 lost objects by resubmitting their tasks. To disable object reconstruction, set @ray.remote(max_retries=0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 709, in <module>\n",
      "    monitor.run()\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 584, in run\n",
      "    self._run()\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 438, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n",
      "\u001b[33m(raylet)\u001b[0m The node with node id: 62ed90001940ccecf3f5dc0563de3c42fcbf3c8da4236b9afba265a4 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hpo(\n",
    "    num_samples=5,\n",
    "    num_epochs=100,\n",
    "    logger=\"lightning\",\n",
    "    wandb_project=\"hanging-runs-test-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with `logger=\"ray\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-16 10:56:21</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:54.93        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.4/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_4195c_00000</td><td>TERMINATED</td><td>127.0.0.1:80344</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.000218637</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         28.9673</td><td style=\"text-align: right;\"> 0.0153974  </td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.0149912 </td></tr>\n",
       "<tr><td>train_tune_4195c_00001</td><td>TERMINATED</td><td>127.0.0.1:80342</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.00278689 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         39.1092</td><td style=\"text-align: right;\"> 6.27668e-05</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.193806  </td></tr>\n",
       "<tr><td>train_tune_4195c_00002</td><td>TERMINATED</td><td>127.0.0.1:80341</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">    0.0370517  </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         28.746 </td><td style=\"text-align: right;\"> 9.92846e-05</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.00479408</td></tr>\n",
       "<tr><td>train_tune_4195c_00003</td><td>TERMINATED</td><td>127.0.0.1:80339</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    0.0927318  </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         39.4663</td><td style=\"text-align: right;\"> 0.053364   </td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.114765  </td></tr>\n",
       "<tr><td>train_tune_4195c_00004</td><td>TERMINATED</td><td>127.0.0.1:80338</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">    0.000107355</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         23.3767</td><td style=\"text-align: right;\"> 0.433013   </td><td style=\"text-align: right;\">        0.910714</td><td style=\"text-align: right;\">0.436585  </td></tr>\n",
       "<tr><td>train_tune_4195c_00005</td><td>TERMINATED</td><td>127.0.0.1:80345</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.0174977  </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         29.2834</td><td style=\"text-align: right;\"> 4.68385e-06</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.102202  </td></tr>\n",
       "<tr><td>train_tune_4195c_00006</td><td>TERMINATED</td><td>127.0.0.1:80343</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.00633171 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         23.4078</td><td style=\"text-align: right;\"> 0.000101113</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.239583  </td></tr>\n",
       "<tr><td>train_tune_4195c_00007</td><td>TERMINATED</td><td>127.0.0.1:80337</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.00344117 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         38.6077</td><td style=\"text-align: right;\"> 3.74014e-06</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.00310169</td></tr>\n",
       "<tr><td>train_tune_4195c_00008</td><td>TERMINATED</td><td>127.0.0.1:80336</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    0.0282309  </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         38.917 </td><td style=\"text-align: right;\"> 1.93715e-07</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.0284285 </td></tr>\n",
       "<tr><td>train_tune_4195c_00009</td><td>TERMINATED</td><td>127.0.0.1:80340</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.00026302 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         23.3633</td><td style=\"text-align: right;\"> 0.0286161  </td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.0223018 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 10:55:26,154\tINFO wandb.py:319 -- Already logged into W&B.\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m GPU available: True (mps), used: True\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 0 | model   | Sequential       | 1.3 K  | train\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 1.3 K     Trainable params\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 1.3 K     Total params\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 7         Modules in train mode\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=80344)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m 0 | model   | Sequential       | 403    | train\n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m 403       Trainable params\n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m 403       Total params\n",
      "\u001b[36m(train_tune pid=80345)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80341)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80343)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80342)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80336)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80340)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m \n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00004_4_batch_size=64,hidden_dim=16,learning_rate=0.0001_2024-12-16_10-55-26/checkpoint_000000)\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: Tracking run with wandb version 0.18.7\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: Run data is saved locally in /private/tmp/ray/session_2024-12-16_10-55-24_827130_79941/artifacts/2024-12-16_10-55-26/train_tune_2024-12-16_10-55-24/driver_artifacts/train_tune_4195c_00003_3_batch_size=16,hidden_dim=32,learning_rate=0.0927_2024-12-16_10-55-26/wandb/run-20241216_105533-4195c_00003\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: Syncing run train_tune_4195c_00003\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/leap-labs/hanging-runs-test-2\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: üöÄ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/4195c_00003\n",
      "\u001b[36m(train_tune pid=80340)\u001b[0m GPU available: True (mps), used: True\u001b[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_tune pid=80340)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80340)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m   | Name    | Type             | Params | Mode \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m -----------------------------------------------------\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 0 | model   | Sequential       | 17.5 K | train\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 17.5 K    Trainable params\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 0         Non-trainable params\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 17.5 K    Total params\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 0.070     Total estimated model params size (MB)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 7         Modules in train mode\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m 0         Modules in eval mode\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80340)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80341)\u001b[0m 0 | model   | Sequential       | 403    | train\n",
      "\u001b[36m(train_tune pid=80341)\u001b[0m 403       Trainable params\n",
      "\u001b[36m(train_tune pid=80341)\u001b[0m 403       Total params\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00003_3_batch_size=16,hidden_dim=32,learning_rate=0.0927_2024-12-16_10-55-26/checkpoint_000003)\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Tracking run with wandb version 0.18.7\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Run data is saved locally in /private/tmp/ray/session_2024-12-16_10-55-24_827130_79941/artifacts/2024-12-16_10-55-26/train_tune_2024-12-16_10-55-24/driver_artifacts/train_tune_4195c_00007_7_batch_size=16,hidden_dim=128,learning_rate=0.0034_2024-12-16_10-55-26/wandb/run-20241216_105534-4195c_00007\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Syncing run train_tune_4195c_00007\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: üöÄ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/4195c_00007\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80345)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00005_5_batch_size=32,hidden_dim=128,learning_rate=0.0175_2024-12-16_10-55-26/checkpoint_000047)\u001b[32m [repeated 427x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80345)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00005_5_batch_size=32,hidden_dim=128,learning_rate=0.0175_2024-12-16_10-55-26/checkpoint_000113)\u001b[32m [repeated 629x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80345)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00005_5_batch_size=32,hidden_dim=128,learning_rate=0.0175_2024-12-16_10-55-26/checkpoint_000177)\u001b[32m [repeated 616x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80343)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00006_6_batch_size=64,hidden_dim=64,learning_rate=0.0063_2024-12-16_10-55-26/checkpoint_000321)\u001b[32m [repeated 720x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80345)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00005_5_batch_size=32,hidden_dim=128,learning_rate=0.0175_2024-12-16_10-55-26/checkpoint_000335)\u001b[32m [repeated 763x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80340)\u001b[0m `Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                                                                                \n",
      "\u001b[36m(train_tune pid=80345)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00005_5_batch_size=32,hidden_dim=128,learning_rate=0.0175_2024-12-16_10-55-26/checkpoint_000415)\u001b[32m [repeated 697x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: Run history:\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:         time_this_iter_s ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:           train_accuracy ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:             val_accuracy ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: Run summary:\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                    epoch 499\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: iterations_since_restore 500\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                     step 1000\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:       time_since_restore 23.36335\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:         time_this_iter_s 0.03447\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:             time_total_s 23.36335\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                timestamp 1734346566\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:           train_accuracy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:               train_loss 0.02862\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:       training_iteration 500\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:             val_accuracy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb:                 val_loss 0.0223\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: üöÄ View run train_tune_4195c_00009 at: https://wandb.ai/leap-labs/hanging-runs-test-2/runs/4195c_00009\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/leap-labs/hanging-runs-test-2\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[36m(_WandbLoggingActor pid=80432)\u001b[0m wandb: Find logs at: ./wandb/run-20241216_105534-4195c_00009/logs\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:         time_this_iter_s ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:           train_accuracy ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:               train_loss ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:             val_accuracy ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80400)\u001b[0m wandb:                 val_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:         time_this_iter_s ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:           train_accuracy ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:               train_loss ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:             val_accuracy ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                 val_loss ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\n",
      "\u001b[36m(train_tune pid=80338)\u001b[0m `Trainer.fit` stopped: `max_epochs=500` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: \u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00003_3_batch_size=16,hidden_dim=32,learning_rate=0.0927_2024-12-16_10-55-26/checkpoint_000358)\u001b[32m [repeated 556x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: Run history:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: Run summary:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                    epoch 499\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: iterations_since_restore 500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                     step 1000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:       time_since_restore 23.4078\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:         time_this_iter_s 0.03416\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:             time_total_s 23.4078\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                timestamp 1734346567\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:           train_accuracy 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:               train_loss 0.0001\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:       training_iteration 500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:             val_accuracy 0.96667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb:                 val_loss 0.23958\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: üöÄ View run train_tune_4195c_00006 at: https://wandb.ai/leap-labs/hanging-runs-test-2/runs/4195c_00006\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80437)\u001b[0m wandb: Find logs at: ./wandb/run-20241216_105534-4195c_00006/logs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:         time_this_iter_s ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:           train_accuracy ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:               train_loss ‚ñÅ‚ñà‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:             val_accuracy ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ\n",
      "\u001b[36m(_WandbLoggingActor pid=80403)\u001b[0m wandb:                 val_loss ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:         time_this_iter_s ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:           train_accuracy ‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:               train_loss ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:             val_accuracy ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                 val_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(train_tune pid=80344)\u001b[0m `Trainer.fit` stopped: `max_epochs=500` reached.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=80339)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00003_3_batch_size=16,hidden_dim=32,learning_rate=0.0927_2024-12-16_10-55-26/checkpoint_000444)\u001b[32m [repeated 339x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: Run history:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: Run summary:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                    epoch 499\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: iterations_since_restore 500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                     step 2000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:       time_since_restore 28.96732\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:         time_this_iter_s 0.03299\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:             time_total_s 28.96732\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                timestamp 1734346572\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:           train_accuracy 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:               train_loss 0.0154\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:       training_iteration 500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:             val_accuracy 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb:                 val_loss 0.01499\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: üöÄ View run train_tune_4195c_00000 at: https://wandb.ai/leap-labs/hanging-runs-test-2/runs/4195c_00000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80404)\u001b[0m wandb: Find logs at: ./wandb/run-20241216_105534-4195c_00000/logs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-12-16 10:56:21,083\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24' in 0.0516s.\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:         time_this_iter_s ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:           train_accuracy ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñà‚ñà‚ñÜ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:               train_loss ‚ñÇ‚ñà‚ñÉ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÇ\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:             val_accuracy ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb:                 val_loss ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m `Trainer.fit` stopped: `max_epochs=500` reached.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80399)\u001b[0m wandb: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:         time_this_iter_s ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:           train_accuracy ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:               train_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:             val_accuracy ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ\n",
      "\u001b[36m(_WandbLoggingActor pid=80407)\u001b[0m wandb:                 val_loss ‚ñÖ‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñá\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:         time_this_iter_s ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:           train_accuracy ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:               train_loss ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:             val_accuracy ‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ\n",
      "\u001b[36m(_WandbLoggingActor pid=80405)\u001b[0m wandb:                 val_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:         time_this_iter_s ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:           train_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:               train_loss ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:             val_accuracy ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                 val_loss ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb: - 0.003 MB of 0.003 MB uploaded\n",
      "\u001b[36m(train_tune pid=80337)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00007_7_batch_size=16,hidden_dim=128,learning_rate=0.0034_2024-12-16_10-55-26/checkpoint_000499)\u001b[32m [repeated 232x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Run history:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Run summary:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                    epoch 499\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: iterations_since_restore 500\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                     step 4000\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:       time_since_restore 38.6077\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:         time_this_iter_s 0.04274\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:             time_total_s 38.6077\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                timestamp 1734346581\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:           train_accuracy 1\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:               train_loss 0.0\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:       training_iteration 500\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:             val_accuracy 1\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                 val_loss 0.0031\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: üöÄ View run train_tune_4195c_00007 at: https://wandb.ai/leap-labs/hanging-runs-test-2/runs/4195c_00007\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: Find logs at: ./wandb/run-20241216_105534-4195c_00007/logs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb: \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=80435)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "wandb:                                                                                \n",
      "2024-12-16 10:56:39,216\tINFO tune.py:1041 -- Total run time: 73.08 seconds (54.88 seconds for the tuning loop).\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb: iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:                     step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:       time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:         time_this_iter_s ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:             time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:                timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:           train_accuracy ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:               train_loss ‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:       training_iteration ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:             val_accuracy ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[36m(_WandbLoggingActor pid=80421)\u001b[0m wandb:                 val_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'hidden_dim': 128, 'learning_rate': 0.003441166328557567, 'batch_size': 16}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">096d6641-train</strong> at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2/runs/vfbz3jrq' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2/runs/vfbz3jrq</a><br/> View project at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241216_105524-vfbz3jrq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 3.7401368899736553e-06, 'train_accuracy': 1.0, 'val_loss': 0.0031016869470477104, 'val_accuracy': 1.0, 'epoch': 499, 'step': 4000},\n",
       "  path='/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00007_7_batch_size=16,hidden_dim=128,learning_rate=0.0034_2024-12-16_10-55-26',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_10-55-24/train_tune_4195c_00007_7_batch_size=16,hidden_dim=128,learning_rate=0.0034_2024-12-16_10-55-26/checkpoint_000499)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpo(\n",
    "    num_samples=5,\n",
    "    num_epochs=100,\n",
    "    logger=\"ray\",\n",
    "    wandb_project=\"hanging-runs-test-2\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
