{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update imports when files change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a (relatively) minimal example of using Ray Tune and Pytorch Lightning to train a fully connected network with optimal hyperparameters on an iris dataset.\n",
    "\n",
    "The `hpo` method is provided to kick off an example training process, and repeated to help test wandb logging within a jupyter notebook.\n",
    "\n",
    "To demonstrate the different methods of logging in this environment, the `logger` argument is provided.\n",
    "\n",
    "- `logger=\"lightning` will use the `lightning.pytorch.loggers.WandbLogger` module to log the results within each HPO trial.\n",
    "- `logger=\"ray\"` will use the `ray.air.integrations.wandb.WandbLoggerCallback` module to log the results as part of the HPO Tuner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpo import hpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First run with `logger=\"lightning\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-16 11:50:57</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:09.91        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.8/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">   val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_fd4fc_00000</td><td>TERMINATED</td><td>127.0.0.1:99759</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">    0.0306992  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         6.23526</td><td style=\"text-align: right;\"> 0.0135901  </td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.13997    </td></tr>\n",
       "<tr><td>train_tune_fd4fc_00001</td><td>TERMINATED</td><td>127.0.0.1:99761</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.0283394  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         4.70377</td><td style=\"text-align: right;\"> 4.07366e-05</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.000592346</td></tr>\n",
       "<tr><td>train_tune_fd4fc_00002</td><td>TERMINATED</td><td>127.0.0.1:99760</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.00170055 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         4.65612</td><td style=\"text-align: right;\"> 0.0696097  </td><td style=\"text-align: right;\">        0.958333</td><td style=\"text-align: right;\">0.0129232  </td></tr>\n",
       "<tr><td>train_tune_fd4fc_00003</td><td>TERMINATED</td><td>127.0.0.1:99762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    0.000311506</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         3.91716</td><td style=\"text-align: right;\"> 0.590235   </td><td style=\"text-align: right;\">        0.875   </td><td style=\"text-align: right;\">0.611679   </td></tr>\n",
       "<tr><td>train_tune_fd4fc_00004</td><td>TERMINATED</td><td>127.0.0.1:99758</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.0402234  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         3.97452</td><td style=\"text-align: right;\"> 0.000271984</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.00260228 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_tune pid=99762)\u001b[0m GPU available: True (mps), used: True\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: Tracking run with wandb version 0.18.7\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: Run data is saved locally in ./wandb/run-20241216_115051-vosk808g\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: Syncing run distinctive-voice-133\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: â­ï¸ View project at https://wandb.ai/leap-labs/hanging-runs-test-2\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m wandb: ğŸš€ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/vosk808g\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m \n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 0 | model   | Sequential       | 1.3 K  | train\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 1.3 K     Trainable params\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 1.3 K     Total params\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 7         Modules in train mode\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=99760)\u001b[0m \n",
      "\u001b[36m(train_tune pid=99758)\u001b[0m \n",
      "\u001b[36m(train_tune pid=99761)\u001b[0m \n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m \n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 0 | model   | Sequential       | 403    | train\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 403       Trainable params\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 403       Total params\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-50-46/train_tune_fd4fc_00003_3_batch_size=64,hidden_dim=32,learning_rate=0.0003_2024-12-16_11-50-47/checkpoint_000000)\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-50-46/train_tune_fd4fc_00003_3_batch_size=64,hidden_dim=32,learning_rate=0.0003_2024-12-16_11-50-47/checkpoint_000001)\n",
      "\u001b[36m(train_tune pid=99762)\u001b[0m `Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m GPU available: True (mps), used: True\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: Tracking run with wandb version 0.18.7\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: Run data is saved locally in ./wandb/run-20241216_115051-dwrs1hqs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: Syncing run dark-paper-135\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: â­ï¸ View project at https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m wandb: ğŸš€ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/dwrs1hqs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m   | Name    | Type             | Params | Mode \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m -----------------------------------------------------\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99761)\u001b[0m 0 | model   | Sequential       | 4.7 K  | train\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99761)\u001b[0m 4.7 K     Trainable params\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 0         Non-trainable params\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99761)\u001b[0m 4.7 K     Total params\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 0.002     Total estimated model params size (MB)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 7         Modules in train mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m 0         Modules in eval mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "2024-12-16 11:50:57,495\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-50-46' in 0.0120s.\n",
      "2024-12-16 11:50:57,498\tINFO tune.py:1041 -- Total run time: 9.93 seconds (9.90 seconds for the tuning loop).\n",
      "\u001b[36m(train_tune pid=99759)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-50-46/train_tune_fd4fc_00000_0_batch_size=16,hidden_dim=16,learning_rate=0.0307_2024-12-16_11-50-47/checkpoint_000099)\u001b[32m [repeated 498x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'hidden_dim': 64, 'learning_rate': 0.028339440999622784, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f4a7b6e3fd41eb934409cf1cb37734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">4d3f8c6e-train</strong> at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2/runs/8cfi1ig1' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2/runs/8cfi1ig1</a><br/> View project at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241216_115045-8cfi1ig1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 4.073658419656567e-05, 'train_accuracy': 1.0, 'val_loss': 0.000592346244957298, 'val_accuracy': 1.0, 'epoch': 99, 'step': 400},\n",
       "  path='/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-50-46/train_tune_fd4fc_00001_1_batch_size=32,hidden_dim=64,learning_rate=0.0283_2024-12-16_11-50-47',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-50-46/train_tune_fd4fc_00001_1_batch_size=32,hidden_dim=64,learning_rate=0.0283_2024-12-16_11-50-47/checkpoint_000099)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1734350696 ***\n",
      "PC: @        0x18bd33efc  (unknown)  kevent\n",
      "    @        0x15dee3964  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "    @        0x18bda4184  (unknown)  _sigtramp\n",
      "    @        0x1068807ac  (unknown)  select_kqueue_control_impl\n",
      "    @        0x1061579d4  (unknown)  method_vectorcall_FASTCALL\n",
      "    @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1061559e4  (unknown)  method_vectorcall\n",
      "    @        0x10619d244  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10601c250  (unknown)  _PyEval_Vector\n",
      "    @        0x106052514  (unknown)  builtin_exec\n",
      "    @        0x10616b218  (unknown)  cfunction_vectorcall_FASTCALL\n",
      "    @        0x105f88ce4  (unknown)  call_function\n",
      "    @        0x10619d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x105f88ce4  (unknown)  call_function\n",
      "    @        0x10619d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1060a5888  (unknown)  pymain_run_module\n",
      "    @        0x1060a4250  (unknown)  Py_RunMain\n",
      "    @        0x1061befac  (unknown)  Py_BytesMain\n",
      "    @        0x18b9ec274  (unknown)  start\n",
      "[2024-12-16 12:04:56,245 E 99665 133624256] logging.cc:447: *** SIGTERM received at time=1734350696 ***\n",
      "[2024-12-16 12:04:56,246 E 99665 133624256] logging.cc:447: PC: @        0x18bd33efc  (unknown)  kevent\n",
      "[2024-12-16 12:04:56,250 E 99665 133624256] logging.cc:447:     @        0x15dee3a84  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "[2024-12-16 12:04:56,250 E 99665 133624256] logging.cc:447:     @        0x18bda4184  (unknown)  _sigtramp\n",
      "[2024-12-16 12:04:56,250 E 99665 133624256] logging.cc:447:     @        0x1068807ac  (unknown)  select_kqueue_control_impl\n",
      "[2024-12-16 12:04:56,252 E 99665 133624256] logging.cc:447:     @        0x1061579d4  (unknown)  method_vectorcall_FASTCALL\n",
      "[2024-12-16 12:04:56,252 E 99665 133624256] logging.cc:447:     @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,252 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,252 E 99665 133624256] logging.cc:447:     @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,252 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,253 E 99665 133624256] logging.cc:447:     @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,253 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,253 E 99665 133624256] logging.cc:447:     @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,253 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,254 E 99665 133624256] logging.cc:447:     @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,254 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,254 E 99665 133624256] logging.cc:447:     @        0x10619d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,254 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,254 E 99665 133624256] logging.cc:447:     @        0x1061559e4  (unknown)  method_vectorcall\n",
      "[2024-12-16 12:04:56,254 E 99665 133624256] logging.cc:447:     @        0x10619d244  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,255 E 99665 133624256] logging.cc:447:     @        0x10601c250  (unknown)  _PyEval_Vector\n",
      "[2024-12-16 12:04:56,255 E 99665 133624256] logging.cc:447:     @        0x106052514  (unknown)  builtin_exec\n",
      "[2024-12-16 12:04:56,255 E 99665 133624256] logging.cc:447:     @        0x10616b218  (unknown)  cfunction_vectorcall_FASTCALL\n",
      "[2024-12-16 12:04:56,255 E 99665 133624256] logging.cc:447:     @        0x105f88ce4  (unknown)  call_function\n",
      "[2024-12-16 12:04:56,256 E 99665 133624256] logging.cc:447:     @        0x10619d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,256 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,256 E 99665 133624256] logging.cc:447:     @        0x105f88ce4  (unknown)  call_function\n",
      "[2024-12-16 12:04:56,257 E 99665 133624256] logging.cc:447:     @        0x10619d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 12:04:56,257 E 99665 133624256] logging.cc:447:     @        0x105fbf08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 12:04:56,257 E 99665 133624256] logging.cc:447:     @        0x1060a5888  (unknown)  pymain_run_module\n",
      "[2024-12-16 12:04:56,257 E 99665 133624256] logging.cc:447:     @        0x1060a4250  (unknown)  Py_RunMain\n",
      "[2024-12-16 12:04:56,257 E 99665 133624256] logging.cc:447:     @        0x1061befac  (unknown)  Py_BytesMain\n",
      "[2024-12-16 12:04:56,257 E 99665 133624256] logging.cc:447:     @        0x18b9ec274  (unknown)  start\n",
      "[2024-12-16 12:04:56,353 E 99665 133624910] core_worker.cc:786: :info_message: Attempting to recover 3 lost objects by resubmitting their tasks. To disable object reconstruction, set @ray.remote(max_retries=0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 709, in <module>\n",
      "    monitor.run()\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 584, in run\n",
      "    self._run()\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 438, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n",
      "\u001b[33m(raylet)\u001b[0m The node with node id: a8efa22efce3e433132e39a22dcf0c9af544ef97af47003925c7308a and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hpo(\n",
    "    num_samples=5,\n",
    "    num_epochs=100,\n",
    "    logger=\"lightning\",\n",
    "    wandb_project=\"hanging-runs-test-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with `logger=\"ray\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-16 11:41:55</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:12.25        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.8/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">   val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_b914a_00000</td><td>TERMINATED</td><td>127.0.0.1:97379</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.000452254</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         3.8035 </td><td style=\"text-align: right;\"> 0.0835721  </td><td style=\"text-align: right;\">        0.946429</td><td style=\"text-align: right;\">0.0482867  </td></tr>\n",
       "<tr><td>train_tune_b914a_00001</td><td>TERMINATED</td><td>127.0.0.1:97376</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    0.0637449  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         4.65926</td><td style=\"text-align: right;\"> 0.00316244 </td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.000540304</td></tr>\n",
       "<tr><td>train_tune_b914a_00002</td><td>TERMINATED</td><td>127.0.0.1:97377</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    0.0257644  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         4.51095</td><td style=\"text-align: right;\"> 0.00399401 </td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.000114948</td></tr>\n",
       "<tr><td>train_tune_b914a_00003</td><td>TERMINATED</td><td>127.0.0.1:97378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">    0.00495999 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         6.0591 </td><td style=\"text-align: right;\"> 0.000206157</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.0102332  </td></tr>\n",
       "<tr><td>train_tune_b914a_00004</td><td>TERMINATED</td><td>127.0.0.1:97380</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    0.0941822  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         4.47387</td><td style=\"text-align: right;\"> 7.30129e-06</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">0.000385179</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:41:43,613\tINFO wandb.py:319 -- Already logged into W&B.\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m GPU available: True (mps), used: True\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m \n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 0 | model   | Sequential       | 1.3 K  | train\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 1.3 K     Trainable params\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 1.3 K     Total params\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 7         Modules in train mode\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=97376)\u001b[0m \n",
      "\u001b[36m(train_tune pid=97379)\u001b[0m \n",
      "\u001b[36m(train_tune pid=97380)\u001b[0m \n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m \n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 0 | model   | Sequential       | 403    | train\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 403       Trainable params\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 403       Total params\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-41-42/train_tune_b914a_00002_2_batch_size=32,hidden_dim=32,learning_rate=0.0258_2024-12-16_11-41-43/checkpoint_000000)\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: Tracking run with wandb version 0.18.7\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: Run data is saved locally in /private/tmp/ray/session_2024-12-16_11-41-42_395601_97230/artifacts/2024-12-16_11-41-43/train_tune_2024-12-16_11-41-42/driver_artifacts/train_tune_b914a_00002_2_batch_size=32,hidden_dim=32,learning_rate=0.0258_2024-12-16_11-41-43/wandb/run-20241216_114148-b914a_00002\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: Syncing run train_tune_b914a_00002\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: â­ï¸ View project at https://wandb.ai/leap-labs/hanging-runs-test-2\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: ğŸš€ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/b914a_00002\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m GPU available: True (mps), used: True\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m   | Name    | Type             | Params | Mode \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m -----------------------------------------------------\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97380)\u001b[0m 0 | model   | Sequential       | 1.3 K  | train\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97380)\u001b[0m 1.3 K     Trainable params\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 0         Non-trainable params\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97380)\u001b[0m 1.3 K     Total params\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 0.002     Total estimated model params size (MB)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 7         Modules in train mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m 0         Modules in eval mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97378)\u001b[0m /Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97377)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-41-42/train_tune_b914a_00002_2_batch_size=32,hidden_dim=32,learning_rate=0.0258_2024-12-16_11-41-43/checkpoint_000070)\u001b[32m [repeated 330x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: Currently logged in as: robbie-leap (leap-labs). Use `wandb login --relogin` to force relogin\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_tune pid=97379)\u001b[0m `Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: Tracking run with wandb version 0.18.7\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: Run data is saved locally in /private/tmp/ray/session_2024-12-16_11-41-42_395601_97230/artifacts/2024-12-16_11-41-43/train_tune_2024-12-16_11-41-42/driver_artifacts/train_tune_b914a_00003_3_batch_size=16,hidden_dim=16,learning_rate=0.0050_2024-12-16_11-41-43/wandb/run-20241216_114148-b914a_00003\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: Syncing run train_tune_b914a_00003\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: â­ï¸ View project at https://wandb.ai/leap-labs/hanging-runs-test-2\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: ğŸš€ View run at https://wandb.ai/leap-labs/hanging-runs-test-2/runs/b914a_00003\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                                                                                \n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: Run history:\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                    epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: iterations_since_restore â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                     step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:       time_since_restore â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:         time_this_iter_s â–…â–„â–…â–…â–†â–ƒâ–„â–„â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–â–ˆâ–ƒâ–â–â–â–‚â–â–â–‚\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:             time_total_s â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                timestamp â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:           train_accuracy â–â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:               train_loss â–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:       training_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:             val_accuracy â–â–„â–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                 val_loss â–ˆâ–ˆâ–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: Run summary:\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                    epoch 99\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: iterations_since_restore 100\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                     step 200\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:       time_since_restore 3.8035\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:         time_this_iter_s 0.02257\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:             time_total_s 3.8035\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                timestamp 1734349313\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:           train_accuracy 0.94643\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:               train_loss 0.08357\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:       training_iteration 100\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:             val_accuracy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb:                 val_loss 0.04829\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: ğŸš€ View run train_tune_b914a_00000 at: https://wandb.ai/leap-labs/hanging-runs-test-2/runs/b914a_00000\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: â­ï¸ View project at: https://wandb.ai/leap-labs/hanging-runs-test-2\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[36m(_WandbLoggingActor pid=97416)\u001b[0m wandb: Find logs at: ./wandb/run-20241216_114148-b914a_00000/logs\n",
      "2024-12-16 11:41:55,867\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-41-42' in 0.0169s.\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:                    epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb: iterations_since_restore â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:                     step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:       time_since_restore â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:         time_this_iter_s â–ˆâ–‡â–†â–„â–„â–„â–„â–„â–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚â–â–‚â–ƒâ–â–â–â–â–‚\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:             time_total_s â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:           train_accuracy â–â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:               train_loss â–ˆâ–„â–‚â–â–â–â–‚â–ƒâ–â–â–â–‚â–‚â–â–â–â–â–ƒâ–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:       training_iteration â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:             val_accuracy â–â–…â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97364)\u001b[0m wandb:                 val_loss â–ˆâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:                    epoch â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb: iterations_since_restore â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:                     step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:       time_since_restore â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:         time_this_iter_s â–ˆâ–ˆâ–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–„â–â–â–â–â–â–‚â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:             time_total_s â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:           train_accuracy â–‚â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:               train_loss â–ˆâ–†â–†â–‚â–‚â–â–‚â–‚â–‚â–„â–ƒâ–‚â–â–ƒâ–â–„â–â–â–â–‚â–â–„â–‚â–â–â–â–â–„â–„â–‚â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:       training_iteration â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:             val_accuracy â–â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97413)\u001b[0m wandb:                 val_loss â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:                    epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb: iterations_since_restore â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:                     step â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:       time_since_restore â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:         time_this_iter_s â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ˆâ–ƒâ–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:             time_total_s â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:           train_accuracy â–â–ˆâ–…â–ˆâ–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:               train_loss â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–„â–â–‚â–ƒâ–…â–‚â–‚â–…â–„â–„â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:       training_iteration â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:             val_accuracy â–â–ˆâ–†â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97418)\u001b[0m wandb:                 val_loss â–ˆâ–‚â–‚â–‚â–â–‡â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–‚â–„â–‚â–„â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "2024-12-16 11:41:57,588\tINFO tune.py:1041 -- Total run time: 13.99 seconds (12.24 seconds for the tuning loop).\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:                    epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb: iterations_since_restore â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:                     step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:       time_since_restore â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:         time_this_iter_s â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:             time_total_s â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:           train_accuracy â–â–ˆâ–ƒâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–†â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ƒâ–†â–ˆâ–ˆâ–†\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:               train_loss â–ˆâ–…â–„â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–‚â–â–ƒâ–‚â–â–â–â–‚â–â–ƒâ–â–â–\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:       training_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:             val_accuracy â–â–‚â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[36m(_WandbLoggingActor pid=97421)\u001b[0m wandb:                 val_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'hidden_dim': 32, 'learning_rate': 0.025764370842881416, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">5c82a37f-train</strong> at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2/runs/l8g0xrab' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2/runs/l8g0xrab</a><br/> View project at: <a href='https://wandb.ai/leap-labs/hanging-runs-test-2' target=\"_blank\">https://wandb.ai/leap-labs/hanging-runs-test-2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241216_114141-l8g0xrab/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 0.003994013648480177, 'train_accuracy': 1.0, 'val_loss': 0.00011494827049318701, 'val_accuracy': 1.0, 'epoch': 99, 'step': 400},\n",
       "  path='/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-41-42/train_tune_b914a_00002_2_batch_size=32,hidden_dim=32,learning_rate=0.0258_2024-12-16_11-41-43',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/Users/robbiemccorkell/ray_results/train_tune_2024-12-16_11-41-42/train_tune_b914a_00002_2_batch_size=32,hidden_dim=32,learning_rate=0.0258_2024-12-16_11-41-43/checkpoint_000099)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1734349395 ***\n",
      "PC: @        0x18bd33efc  (unknown)  kevent\n",
      "    @        0x152f5b964  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "    @        0x18bda4184  (unknown)  _sigtramp\n",
      "    @        0x101f607ac  (unknown)  select_kqueue_control_impl\n",
      "    @        0x1018379d4  (unknown)  method_vectorcall_FASTCALL\n",
      "    @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x1018359e4  (unknown)  method_vectorcall\n",
      "    @        0x10187d244  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x1016fc250  (unknown)  _PyEval_Vector\n",
      "    @        0x101732514  (unknown)  builtin_exec\n",
      "    @        0x10184b218  (unknown)  cfunction_vectorcall_FASTCALL\n",
      "    @        0x101668ce4  (unknown)  call_function\n",
      "    @        0x10187d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x101668ce4  (unknown)  call_function\n",
      "    @        0x10187d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "    @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "    @        0x101785888  (unknown)  pymain_run_module\n",
      "    @        0x101784250  (unknown)  Py_RunMain\n",
      "    @        0x10189efac  (unknown)  Py_BytesMain\n",
      "    @        0x18b9ec274  (unknown)  start\n",
      "[2024-12-16 11:43:15,460 E 97230 133603934] logging.cc:447: *** SIGTERM received at time=1734349395 ***\n",
      "[2024-12-16 11:43:15,460 E 97230 133603934] logging.cc:447: PC: @        0x18bd33efc  (unknown)  kevent\n",
      "[2024-12-16 11:43:15,460 E 97230 133603934] logging.cc:447:     @        0x152f5ba84  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "[2024-12-16 11:43:15,460 E 97230 133603934] logging.cc:447:     @        0x18bda4184  (unknown)  _sigtramp\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x101f607ac  (unknown)  select_kqueue_control_impl\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x1018379d4  (unknown)  method_vectorcall_FASTCALL\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,461 E 97230 133603934] logging.cc:447:     @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10187d130  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x1018359e4  (unknown)  method_vectorcall\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10187d244  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x1016fc250  (unknown)  _PyEval_Vector\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x101732514  (unknown)  builtin_exec\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10184b218  (unknown)  cfunction_vectorcall_FASTCALL\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x101668ce4  (unknown)  call_function\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10187d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x101668ce4  (unknown)  call_function\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10187d70c  (unknown)  _PyEval_EvalFrameDefault\n",
      "[2024-12-16 11:43:15,462 E 97230 133603934] logging.cc:447:     @        0x10169f08c  (unknown)  _PyFunction_Vectorcall\n",
      "[2024-12-16 11:43:15,463 E 97230 133603934] logging.cc:447:     @        0x101785888  (unknown)  pymain_run_module\n",
      "[2024-12-16 11:43:15,463 E 97230 133603934] logging.cc:447:     @        0x101784250  (unknown)  Py_RunMain\n",
      "[2024-12-16 11:43:15,463 E 97230 133603934] logging.cc:447:     @        0x10189efac  (unknown)  Py_BytesMain\n",
      "[2024-12-16 11:43:15,463 E 97230 133603934] logging.cc:447:     @        0x18b9ec274  (unknown)  start\n",
      "[2024-12-16 11:43:15,515 E 97230 133605093] core_worker.cc:786: :info_message: Attempting to recover 3 lost objects by resubmitting their tasks. To disable object reconstruction, set @ray.remote(max_retries=0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 709, in <module>\n",
      "    monitor.run()\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 584, in run\n",
      "    self._run()\n",
      "  File \"/Users/robbiemccorkell/Developer/robbiemccorkell/wandb-jupyter/.venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 438, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n",
      "\u001b[33m(raylet)\u001b[0m The node with node id: 08cb723c299318fd3d9104f53ceeb9f96b8b73819ed52b4b67c2fab2 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hpo(\n",
    "    num_samples=5,\n",
    "    num_epochs=100,\n",
    "    logger=\"ray\",\n",
    "    wandb_project=\"hanging-runs-test-2\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
